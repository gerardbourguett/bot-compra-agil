# Plan de Escalabilidad y Mejoras SaaS - CompraAgil

**Fecha:** 2025-12-28
**Autor:** DiseÃ±o colaborativo con Claude Code
**Estado:** DiseÃ±o aprobado, pendiente implementaciÃ³n

---

## Ãndice

1. [Contexto y Objetivos](#contexto-y-objetivos)
2. [Arquitectura de Persistencia de Datos](#arquitectura-de-persistencia-de-datos)
3. [OptimizaciÃ³n de Base de Datos y Caching](#optimizaciÃ³n-de-base-de-datos-y-caching)
4. [Arquitectura de Workers y Queue de Tareas](#arquitectura-de-workers-y-queue-de-tareas)
5. [Mejoras de IA y Features Premium](#mejoras-de-ia-y-features-premium)
6. [IntegraciÃ³n con Stack de Monitoreo](#integraciÃ³n-con-stack-de-monitoreo)
7. [Plan de ImplementaciÃ³n por Fases](#plan-de-implementaciÃ³n-por-fases)

---

## Contexto y Objetivos

### SituaciÃ³n Actual

CompraAgil es un SaaS de inteligencia de licitaciones pÃºblicas chilenas con:
- **Bot de Telegram** con comandos interactivos y anÃ¡lisis IA
- **API REST v3** con 40+ endpoints
- **Base de datos PostgreSQL** con 10.6M de registros histÃ³ricos
- **Sistema ML/AI**: Precio Ã³ptimo, RAG histÃ³rico, anÃ¡lisis de competencia
- **Sistema de suscripciones**: 4 tiers (FREE, EMPRENDEDOR, PYME, PROFESIONAL)

### Infraestructura Actual

- **Servidor:** VPS Vultr ($25/mes) con recursos compartidos para mÃºltiples SaaS
- **OrquestaciÃ³n:** Docker Compose con servicios (bot, scraper, PostgreSQL)
- **CI/CD:** GitHub Actions con self-hosted runner
- **Monitoreo existente:** Traefik, Prometheus, Grafana, Loki/Promtail, Uptime Kuma, Portainer

### Pain Points Identificados

1. **Reseteo de BD en deploys** (crÃ­tico): Riesgo de perder 10.6M registros histÃ³ricos
2. **Performance con alta concurrencia**: Queries lentas, bot bloqueado en anÃ¡lisis ML
3. **Falta de visibilidad**: No hay mÃ©tricas de negocio (conversiÃ³n, uso de features)
4. **Features IA bÃ¡sicas**: Matching por keyword, anÃ¡lisis de precios simple

### Objetivos del Plan

1. **Persistencia bulletproof**: Garantizar que nunca se pierdan datos histÃ³ricos
2. **Performance**: Queries <1s, bot siempre responsivo
3. **Escalabilidad**: Preparar para 10x-100x mÃ¡s usuarios
4. **DiferenciaciÃ³n**: Features IA premium para monetizaciÃ³n
5. **Observabilidad**: MÃ©tricas de negocio en tiempo real

---

## Arquitectura de Persistencia de Datos

### Problema

Actualmente existe riesgo de pÃ©rdida de datos por:
- VolÃºmenes Docker huÃ©rfanos (cambio de nombre de proyecto)
- MigraciÃ³n a otro servidor (volÃºmenes no se transfieren)
- Corrupciones de disco
- Limpieza accidental (`docker volume prune`)

### SoluciÃ³n: Arquitectura de 3 Capas

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CAPA 1: Volumen Docker (OperaciÃ³n diaria)         â”‚
â”‚  compra_agil_postgres_data                          â”‚
â”‚  â€¢ Acceso rÃ¡pido                                    â”‚
â”‚  â€¢ Usado por PostgreSQL en runtime                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ Backup automÃ¡tico cada deploy
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CAPA 2: Backups locales (RecuperaciÃ³n rÃ¡pida)     â”‚
â”‚  backups/backup_YYYYMMDD_HHMMSS.sql                â”‚
â”‚  â€¢ Ãšltimos 7 backups rotados automÃ¡ticamente        â”‚
â”‚  â€¢ RestauraciÃ³n en < 5 minutos                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ Subida automÃ¡tica cada deploy
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CAPA 3: Storage externo (Disaster recovery)       â”‚
â”‚  GitHub Artifacts / S3 / Backblaze B2              â”‚
â”‚  â€¢ Backups mensuales comprimidos                    â”‚
â”‚  â€¢ HistÃ³rico completo con datos histÃ³ricos          â”‚
â”‚  â€¢ RecuperaciÃ³n ante pÃ©rdida total del servidor     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Mejoras al CI/CD

1. **Pre-deploy check**: Verificar que volumen existe antes de `docker compose down`
2. **Backup obligatorio**: Deploy falla si no se puede crear backup
3. **Post-deploy verification**: Confirmar conteo de registros post-deploy
4. **Backup upload**: Subir backups a GitHub Artifacts o almacenamiento externo

### Script de RestauraciÃ³n

```bash
# scripts/restore_backup.sh
#!/bin/bash
# Restaurar desde backup local o GitHub Artifacts
# Uso: ./scripts/restore_backup.sh [backup_file.sql.gz]
```

---

## OptimizaciÃ³n de Base de Datos y Caching

### Particionamiento de Tabla HistÃ³rica

Con 10.6M de registros, particionar por mes mejora performance dramÃ¡ticamente:

```sql
-- Convertir a tabla particionada
CREATE TABLE historico_licitaciones (
    id SERIAL,
    fecha_cierre DATE NOT NULL,
    producto_cotizado TEXT,
    monto_total INTEGER,
    -- ... otras columnas
) PARTITION BY RANGE (fecha_cierre);

-- Crear particiones mensuales
CREATE TABLE historico_licitaciones_2024_01
  PARTITION OF historico_licitaciones
  FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');

CREATE TABLE historico_licitaciones_2024_02
  PARTITION OF historico_licitaciones
  FOR VALUES FROM ('2024-02-01') TO ('2024-03-01');
-- ... etc
```

**Ventajas:**
- Queries filtradas por fecha solo escanean una particiÃ³n (10-100x mÃ¡s rÃ¡pido)
- Ãndices mÃ¡s pequeÃ±os por particiÃ³n
- Backups incrementales por mes

### Ãndices Optimizados

Ãndices crÃ­ticos para queries ML/RAG:

```sql
-- BÃºsqueda de productos (RAG) con fuzzy matching
CREATE EXTENSION IF NOT EXISTS pg_trgm;
CREATE INDEX idx_historico_producto_trgm
  ON historico_licitaciones
  USING gin(producto_cotizado gin_trgm_ops);

-- AnÃ¡lisis de precios (lookup rÃ¡pido)
CREATE INDEX idx_historico_precio_lookup
  ON historico_licitaciones
  (producto_cotizado, es_ganador, monto_total, fecha_cierre DESC);

-- Filtros por regiÃ³n
CREATE INDEX idx_historico_region_fecha
  ON historico_licitaciones
  (region, fecha_cierre DESC);

-- BÃºsqueda por organismo
CREATE INDEX idx_historico_organismo
  ON historico_licitaciones
  USING gin(nombre_cotizacion gin_trgm_ops);
```

### Estrategia de Caching con Redis

```
Usuario solicita anÃ¡lisis de precio de "computadores"
    â†“
[Cache L1: Redis - TTL 1 hora]
  â€¢ Key: "ml:precio:computadores:hash"
  â€¢ Hit? â†’ Retornar inmediatamente (50-200ms)
  â€¢ Miss? â†’ Continuar â†“
    â†“
[PostgreSQL Query + ML Processing]
  â€¢ Query a historico_licitaciones (2-5s)
  â€¢ CÃ¡lculo de precio Ã³ptimo (1-3s)
    â†“
[Guardar en Redis para prÃ³xima vez]
  â€¢ TTL: 1 hora para datos cambiantes
  â€¢ TTL: 24 horas para histÃ³rico estable
```

**Datos a cachear con prioridad:**
- Resultados de ML (precio Ã³ptimo, competencia) - TTL: 1h
- BÃºsquedas RAG frecuentes - TTL: 1h
- Listados de licitaciones activas - TTL: 15min
- EstadÃ­sticas de dashboard - TTL: 1h
- Embeddings de productos - TTL: 24h

### Query Optimization Patterns

**âŒ AntipatrÃ³n (lento):**
```python
# Carga TODOS los registros en memoria
cursor.execute(
    "SELECT * FROM historico_licitaciones WHERE producto_cotizado LIKE %s",
    ('%computador%',)
)
all_records = cursor.fetchall()  # 100,000+ registros
```

**âœ… PatrÃ³n optimizado:**
```python
# Limitar resultados + usar Ã­ndices + filtro temporal
cursor.execute("""
    SELECT producto_cotizado, monto_total, cantidad, fecha_cierre
    FROM historico_licitaciones
    WHERE producto_cotizado % %s  -- Similaridad fuzzy (pg_trgm)
    AND fecha_cierre >= NOW() - INTERVAL '2 years'
    AND es_ganador = true
    ORDER BY fecha_cierre DESC
    LIMIT 1000
""", (search_term,))
```

---

## Arquitectura de Workers y Queue de Tareas

### Problema Actual

El bot y scraper corren sÃ­ncronamente. Si un usuario solicita anÃ¡lisis ML pesado (10-15s), el bot se bloquea y no puede responder a otros usuarios.

### SoluciÃ³n: Celery + Redis

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Telegram Bot   â”‚ â† Responde instantÃ¡neamente
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Encola tarea
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Redis Queue    â”‚ â† Broker de mensajes
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Consume tareas
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Celery Workers (3 tipos)           â”‚
â”‚                                     â”‚
â”‚  Worker 1: ML Tasks (2 workers)     â”‚
â”‚  - /precio (cÃ¡lculo Ã³ptimo)         â”‚
â”‚  - /rag (bÃºsqueda histÃ³rica)        â”‚
â”‚  - /competencia (anÃ¡lisis)          â”‚
â”‚  - /scoring (probabilidad ganar)    â”‚
â”‚                                     â”‚
â”‚  Worker 2: Scraping (1 worker)      â”‚
â”‚  - Scraper cada 6h                  â”‚
â”‚  - Import histÃ³rico mensual         â”‚
â”‚                                     â”‚
â”‚  Worker 3: Exports & Reports        â”‚
â”‚  - GeneraciÃ³n de Excel              â”‚
â”‚  - GeneraciÃ³n de PDF (propuestas)   â”‚
â”‚  - EnvÃ­o de alertas masivas         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ImplementaciÃ³n

**Antes (bloqueante):**
```python
# bot_ml_commands.py
async def precio_command(update, context):
    # Esto toma 10-15 segundos y bloquea el bot
    resultado = calcular_precio_optimo(producto)
    await update.message.reply_text(resultado)
```

**DespuÃ©s (async):**
```python
# bot_ml_commands.py
async def precio_command(update, context):
    await update.message.reply_text(
        "ğŸ”„ Analizando precios histÃ³ricos... (esto tomarÃ¡ ~10 seg)"
    )

    # Encolar tarea en background
    task = tasks.calcular_precio_optimo.delay(producto, user_id)

    # El bot queda libre para otras peticiones
```

**Worker task:**
```python
# src/tasks.py
from celery import Celery

celery = Celery('compra_agil', broker='redis://redis:6379/0')

@celery.task(bind=True, max_retries=3)
def calcular_precio_optimo(self, producto, user_id):
    try:
        # Procesamiento pesado aquÃ­
        resultado = ml_precio_optimo.analizar(producto)

        # Notificar al usuario via Telegram
        bot.send_message(user_id, f"âœ… AnÃ¡lisis completado:\n{resultado}")

        return resultado
    except Exception as e:
        # Reintentar hasta 3 veces con backoff exponencial
        self.retry(exc=e, countdown=2 ** self.request.retries)
```

### docker-compose.yml actualizado

```yaml
services:
  redis:
    image: redis:7-alpine
    restart: unless-stopped
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  bot:
    # ... (igual que antes)

  celery-worker-ml:
    image: ghcr.io/.../bot:latest
    command: celery -A tasks worker --queues=ml --concurrency=2 --loglevel=info
    depends_on:
      - redis
      - postgres
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - TELEGRAM_TOKEN=${TELEGRAM_TOKEN}
      - GEMINI_API_KEY=${GEMINI_API_KEY}

  celery-worker-scraping:
    image: ghcr.io/.../scraper:latest
    command: celery -A tasks worker --queues=scraping --concurrency=1 --loglevel=info
    depends_on:
      - redis
      - postgres

  celery-beat:  # Scheduler para tareas periÃ³dicas
    image: ghcr.io/.../bot:latest
    command: celery -A tasks beat --loglevel=info
    depends_on:
      - redis

volumes:
  redis_data:
```

### Beneficios Inmediatos

1. **Bot siempre responsivo**: No se bloquea esperando ML
2. **PriorizaciÃ³n**: Comandos rÃ¡pidos tienen prioridad sobre exports pesados
3. **Rate limiting natural**: Queue limita carga al servidor
4. **Retry automÃ¡tico**: Si falla un anÃ¡lisis ML, se reintenta
5. **Escalabilidad horizontal**: DespuÃ©s puedes agregar mÃ¡s workers en otro servidor

---

## Mejoras de IA y Features Premium

### 4.1 Matching Inteligente con Embeddings

**Problema:** Alertas funcionan por keyword exacta, pierdes licitaciones relevantes.

**SoluciÃ³n:** Semantic search con embeddings.

```python
# Flujo mejorado de alertas
Usuario configura alerta: "Vendo laptops HP"
    â†“
Generar embedding con Gemini (vector de 768 dimensiones)
Almacenar en PostgreSQL con extensiÃ³n pgvector
    â†“
Nueva licitaciÃ³n: "RenovaciÃ³n tecnolÃ³gica equipamiento informÃ¡tico"
    â†“
Similarity search (cosine distance < 0.3)
âœ… Match encontrado (85% similaridad)
ğŸ”” Notificar al usuario
```

**ImplementaciÃ³n tÃ©cnica:**

```sql
-- Instalar pgvector en PostgreSQL
CREATE EXTENSION IF NOT EXISTS vector;

-- Nueva tabla para embeddings
CREATE TABLE licitacion_embeddings (
    id SERIAL PRIMARY KEY,
    licitacion_id INT REFERENCES licitaciones(id),
    embedding vector(768),  -- DimensiÃ³n de Gemini embeddings
    created_at TIMESTAMP DEFAULT NOW()
);

-- Ãndice para bÃºsqueda rÃ¡pida
CREATE INDEX ON licitacion_embeddings
  USING ivfflat (embedding vector_cosine_ops)
  WITH (lists = 100);

-- Query de bÃºsqueda semÃ¡ntica
SELECT l.*, 1 - (le.embedding <=> query_embedding) AS similarity
FROM licitaciones l
JOIN licitacion_embeddings le ON l.id = le.licitacion_id
WHERE 1 - (le.embedding <=> query_embedding) > 0.75
ORDER BY similarity DESC
LIMIT 20;
```

### 4.2 AnÃ¡lisis de Precios HistÃ³ricos Mejorado

Ya existe `ml_precio_optimo.py`, mejorar con insights accionables:

```python
def analizar_precio_optimo_v2(producto, organismo=None, region=None):
    """
    Retorna anÃ¡lisis completo de precios con insights accionables
    """

    # 1. Buscar productos similares (embeddings + fuzzy)
    productos_similares = buscar_similares_semantico(producto)

    # 2. Filtrar por contexto
    query = """
        SELECT
            monto_total / NULLIF(cantidad, 0) AS precio_unitario,
            nombre_proveedor,
            region,
            fecha_cierre,
            es_ganador
        FROM historico_licitaciones
        WHERE producto_cotizado = ANY(%s)
        AND fecha_cierre >= NOW() - INTERVAL '2 years'
    """

    if organismo:
        query += " AND nombre_cotizacion ILIKE %s"
    if region:
        query += " AND region = %s"

    # 3. AnÃ¡lisis estadÃ­stico
    precios = obtener_datos(query)

    return {
        "precio_sugerido": percentil(precios, 40),  # Sweet spot
        "precio_competitivo": percentil(precios, 25),  # Agresivo
        "precio_seguro": percentil(precios, 60),  # Conservador

        # Insights especÃ­ficos
        "insights": [
            f"âš ï¸ Este organismo suele pagar un {diff}% menos que el promedio nacional",
            f"ğŸ’¡ Los proveedores de {region} ganan el {win_rate}% de las veces",
            f"ğŸ“Š Ãšltimas 10 adjudicaciones: rango ${min:,} - ${max:,}"
        ],

        # Competencia
        "competidores_frecuentes": top_5_proveedores,
        "tu_probabilidad_ganar": calcular_win_probability(user_profile, context)
    }
```

### 4.3 Generador de Propuestas con LLM (Feature Premium)

Joya de la corona para planes PYME/PROFESIONAL:

```python
# Nuevo comando: /generar_propuesta
async def generar_propuesta_command(update, context):
    # Validar tier
    subscription = get_user_subscription(user_id)
    if subscription['tier'] not in ['pyme', 'profesional']:
        await update.message.reply_text(
            "ğŸ”’ Esta funciÃ³n requiere plan PYME o superior\n"
            "Usa /upgrade para mejorar tu plan"
        )
        return

    # Obtener detalles de la licitaciÃ³n
    licitacion = obtener_licitacion(licitacion_id)

    # Obtener perfil del usuario (histÃ³rico de propuestas ganadoras)
    perfil_empresa = obtener_perfil_usuario(user_id)

    # Generar con Gemini
    prompt = f"""
    Eres un experto en licitaciones pÃºblicas chilenas.

    LICITACIÃ“N:
    {licitacion['nombre']}
    Organismo: {licitacion['organismo']}
    Presupuesto: ${licitacion['presupuesto']:,}
    Requisitos tÃ©cnicos:
    {licitacion['especificaciones']}

    EMPRESA:
    {perfil_empresa['descripcion']}
    Experiencia previa: {perfil_empresa['adjudicaciones_pasadas']}

    Genera una propuesta tÃ©cnica profesional que:
    1. Demuestre comprensiÃ³n de los requisitos
    2. Destaque nuestra experiencia relevante
    3. Proponga una soluciÃ³n concreta
    4. Incluya cronograma realista

    Formato: Carta formal para portal ChileCompra
    """

    propuesta = await gemini_ai.generar_texto(prompt)

    # Guardar borrador
    guardar_borrador(user_id, licitacion_id, propuesta)

    # Enviar como documento
    await context.bot.send_document(
        chat_id=user_id,
        document=generar_pdf(propuesta),
        filename=f"propuesta_{licitacion_id}.pdf",
        caption="âœ… Propuesta generada. RevÃ­sala y personalÃ­zala antes de enviar."
    )
```

### 4.4 Scoring de Probabilidad de Ganar (Machine Learning)

Modelo de clasificaciÃ³n entrenado con histÃ³rico:

```python
from sklearn.ensemble import RandomForestClassifier
import pandas as pd
import joblib

def entrenar_modelo_win_probability():
    """
    Features:
    - Precio ofertado vs precio promedio histÃ³rico (ratio)
    - Experiencia previa del proveedor en categorÃ­a
    - RegiÃ³n match (local vs forÃ¡neo)
    - TamaÃ±o del proveedor (PYME vs grande)
    - DÃ­a de la semana de cierre
    - Cantidad de competidores (estimado)

    Target: es_ganador (1/0)
    """

    query = """
        SELECT
            monto_total / promedio_categoria AS precio_ratio,
            COUNT(*) OVER (PARTITION BY rut_proveedor, categoria) AS experiencia,
            CASE WHEN region_proveedor = region_licitacion THEN 1 ELSE 0 END AS local,
            -- ... mÃ¡s features
            es_ganador
        FROM historico_licitaciones_features
    """

    df = pd.read_sql(query, conn)

    X = df.drop('es_ganador', axis=1)
    y = df['es_ganador']

    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X, y)

    # Guardar modelo
    joblib.dump(model, 'models/win_probability_v1.pkl')

    return model

# Usar en comando /analizar
def predecir_probabilidad_ganar(licitacion, usuario):
    model = joblib.load('models/win_probability_v1.pkl')

    features = extraer_features(licitacion, usuario)
    probabilidad = model.predict_proba([features])[0][1]

    return {
        "probabilidad": round(probabilidad * 100, 1),
        "factores_clave": get_feature_importance(model, features),
        "recomendaciones": generar_recomendaciones(features, probabilidad)
    }
```

### DistribuciÃ³n de Features por Tier

| Feature | FREE | EMPRENDEDOR | PYME | PROFESIONAL |
|---------|------|-------------|------|-------------|
| BÃºsqueda bÃ¡sica | âœ… | âœ… | âœ… | âœ… |
| Alertas keyword | âŒ | âœ… (3) | âœ… (10) | âœ… (ilimitado) |
| **Alertas semÃ¡nticas (IA)** | âŒ | âŒ | âœ… | âœ… |
| AnÃ¡lisis precio bÃ¡sico | âœ… (2/dÃ­a) | âœ… (5/dÃ­a) | âœ… (10/dÃ­a) | âœ… (ilimitado) |
| **AnÃ¡lisis precio avanzado** | âŒ | âœ… | âœ… | âœ… |
| **Scoring probabilidad** | âŒ | âŒ | âœ… | âœ… |
| **Generador propuestas** | âŒ | âŒ | âœ… (5/mes) | âœ… (ilimitado) |
| **AnÃ¡lisis competencia** | âŒ | âŒ | âŒ | âœ… |
| API access | âŒ | âŒ | âŒ | âœ… |

---

## IntegraciÃ³n con Stack de Monitoreo

### Infraestructura Existente

El servidor ya cuenta con:
- **Traefik** (reverse proxy)
- **Prometheus + Node Exporter + cAdvisor** (mÃ©tricas)
- **Grafana** (dashboards)
- **Loki + Promtail** (logs centralizados)
- **Uptime Kuma** (uptime monitoring)
- **Portainer** (gestiÃ³n de Docker)

### 5.1 Exponer MÃ©tricas de Prometheus

Agregar endpoint `/metrics` al bot:

```python
# src/metrics_server.py
from prometheus_client import Counter, Histogram, Gauge, generate_latest, REGISTRY
from aiohttp import web
import asyncio

# MÃ©tricas de negocio
command_counter = Counter(
    'compra_agil_commands_total',
    'Total comandos ejecutados',
    ['command', 'tier', 'status']
)

ml_latency = Histogram(
    'compra_agil_ml_duration_seconds',
    'DuraciÃ³n anÃ¡lisis ML',
    ['analysis_type']
)

active_subscriptions = Gauge(
    'compra_agil_subscriptions',
    'Suscripciones activas por tier',
    ['tier']
)

cache_hits = Counter(
    'compra_agil_cache_hits_total',
    'Cache hits/misses',
    ['result']
)

async def metrics_handler(request):
    return web.Response(body=generate_latest(REGISTRY), content_type='text/plain')

async def start_metrics_server():
    app = web.Application()
    app.router.add_get('/metrics', metrics_handler)
    runner = web.AppRunner(app)
    await runner.setup()
    site = web.TCPSite(runner, '0.0.0.0', 8000)
    await site.start()
    print("ğŸ“Š Metrics server running on :8000/metrics")
```

### 5.2 Actualizar docker-compose.yml

```yaml
services:
  bot:
    image: ghcr.io/gerardbourguett/bot-compra-agil/bot:latest
    container_name: compra_agil_bot
    restart: unless-stopped
    networks:
      - default
      - traefik_default  # â† Conectar a red de Traefik
    labels:
      # Prometheus scraping
      - "prometheus.scrape=true"
      - "prometheus.port=8000"
      - "prometheus.path=/metrics"
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8000/metrics', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

networks:
  traefik_default:
    external: true
```

### 5.3 Configurar Prometheus Scraping

Agregar a `/devops/monitoring/prometheus/prometheus.yml`:

```yaml
scrape_configs:
  - job_name: 'compra_agil_bot'
    static_configs:
      - targets: ['compra_agil_bot:8000']
        labels:
          app: 'compra_agil'
          service: 'telegram_bot'

  - job_name: 'compra_agil_scraper'
    static_configs:
      - targets: ['compra_agil_scraper:8000']
        labels:
          app: 'compra_agil'
          service: 'scraper'
```

### 5.4 Logging Estructurado para Loki

```python
# src/logger_config.py
import logging
import json
from datetime import datetime

class LokiFormatter(logging.Formatter):
    """Formato JSON para Promtail/Loki"""
    def format(self, record):
        log_obj = {
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "level": record.levelname,
            "app": "compra_agil",
            "service": "telegram_bot",
            "message": record.getMessage(),
        }

        # Contexto adicional
        for attr in ['user_id', 'tier', 'command', 'duration_ms', 'error']:
            if hasattr(record, attr):
                log_obj[attr] = getattr(record, attr)

        if record.exc_info:
            log_obj['exception'] = self.formatException(record.exc_info)

        return json.dumps(log_obj)

def setup_logging():
    handler = logging.StreamHandler()
    handler.setFormatter(LokiFormatter())

    logger = logging.getLogger('compra_agil')
    logger.addHandler(handler)
    logger.setLevel(logging.INFO)

    return logger
```

### 5.5 Dashboard de Grafana

**MÃ©tricas clave a visualizar:**

1. **Panel: Usuarios Activos por Tier**
   ```promql
   compra_agil_subscriptions
   ```

2. **Panel: Comandos por Segundo**
   ```promql
   rate(compra_agil_commands_total[5m])
   ```

3. **Panel: Latencia ML (p95)**
   ```promql
   histogram_quantile(0.95, compra_agil_ml_duration_seconds_bucket)
   ```

4. **Panel: Cache Hit Rate**
   ```promql
   rate(compra_agil_cache_hits_total{result="hit"}[5m]) /
   rate(compra_agil_cache_hits_total[5m])
   ```

5. **Panel: Features Premium Bloqueadas (ConversiÃ³n)**
   ```promql
   increase(compra_agil_commands_total{status="blocked"}[1h])
   ```

### 5.6 Uptime Kuma Monitors

Agregar en UI de Uptime Kuma:
- **Bot Health**: HTTP monitor a `http://compra_agil_bot:8000/metrics` cada 60s
- **Scraper Health**: TCP monitor a `compra_agil_scraper:8000` cada 120s
- **PostgreSQL**: PostgreSQL monitor directo a puerto 5433
- **Telegram API**: HTTP Keyword monitor a `https://api.telegram.org`

### 5.7 Alertas vÃ­a Telegram

```python
# src/monitoring/alerts.py
import os
from telegram import Bot

ADMIN_CHAT_ID = os.getenv('ADMIN_CHAT_ID')
alert_bot = Bot(token=os.getenv('TELEGRAM_TOKEN'))

async def send_admin_alert(severity: str, message: str, metrics: dict = None):
    """EnvÃ­a alerta al admin usando el mismo bot"""
    icons = {"critical": "ğŸ”´", "warning": "ğŸŸ¡", "info": "ğŸŸ¢", "success": "âœ…"}

    text = f"{icons[severity]} <b>{severity.upper()}</b>\n\n"
    text += f"{message}\n"

    if metrics:
        text += "\nğŸ“Š <b>MÃ©tricas:</b>\n"
        for key, value in metrics.items():
            text += f"  â€¢ {key}: {value}\n"

    await alert_bot.send_message(
        chat_id=ADMIN_CHAT_ID,
        text=text,
        parse_mode='HTML'
    )

# Ejemplos de uso
if new_paid_subscriber:
    await send_admin_alert(
        "success",
        f"ğŸ‰ Nuevo suscriptor PYME!",
        {"Usuario": user_name, "Plan": tier, "Precio": "$9.990"}
    )

if celery_queue > 100:
    await send_admin_alert(
        "warning",
        "Queue de tareas alto",
        {"Pendientes": celery_queue, "Workers": worker_count}
    )
```

---

## Plan de ImplementaciÃ³n por Fases

### Resumen de Prioridades

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AHORA (crÃ­tico):                               â”‚
â”‚  â€¢ Fase 0: EstabilizaciÃ³n                       â”‚
â”‚  â€¢ Fase 1: Persistencia bulletproof             â”‚
â”‚  â€¢ Fase 2: OptimizaciÃ³n BD                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SIGUIENTE (1-2 semanas):                       â”‚
â”‚  â€¢ Fase 3: Monitoreo                            â”‚
â”‚  â€¢ Fase 4: Workers/Queue                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DESPUÃ‰S (1 mes):                               â”‚
â”‚  â€¢ Fase 5: Features IA Premium                  â”‚
â”‚  â€¢ Fase 6: MonetizaciÃ³n                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FUTURO (cuando escales):                       â”‚
â”‚  â€¢ Fase 7: Escalabilidad horizontal             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### FASE 0: EstabilizaciÃ³n (1-2 dÃ­as) ğŸ”§

**Objetivo:** Arreglar lo que estÃ¡ roto antes de construir cosas nuevas.

**Tareas:**
1. âœ… **Arreglar healthchecks** (bot y scraper estÃ¡n unhealthy)
   - Bot: endpoint `/health` o `/metrics`
   - Scraper: verificar conexiÃ³n a BD

2. âœ… **Verificar preservaciÃ³n de volÃºmenes**
   - Test manual: deploy â†’ verificar que datos persisten
   - Agregar step de validaciÃ³n post-deploy en CI/CD

3. âœ… **Configurar logging estructurado**
   - JSON formatter para Loki/Promtail
   - Logs centralizados visibles en Grafana

**Criterios de Ã©xito:**
- [ ] `docker ps` muestra todos los servicios como `healthy`
- [ ] Logs JSON visibles en Grafana Loki
- [ ] Deploy manual exitoso sin pÃ©rdida de datos

**Entregable:** Sistema estable, servicios healthy, logs centralizados funcionando.

---

### FASE 1: Persistencia Bulletproof (2-3 dÃ­as) ğŸ’¾

**Objetivo:** Garantizar que NUNCA se pierdan los datos histÃ³ricos.

**Tareas:**
1. âœ… **Backup automÃ¡tico mejorado**
   - Pre-deploy: backup obligatorio (ya existe parcialmente en lÃ­nea 107 de ci-cd.yml)
   - Post-deploy: verificar que datos siguen ahÃ­ (lÃ­nea 152-154)
   - Fallo del deploy si no hay backup exitoso

2. âœ… **Backup a almacenamiento externo**
   - Subir backups a GitHub Artifacts (gratis, 500MB)
   - Workflow semanal: backup completo comprimido
   - RetenciÃ³n: 4 backups mensuales

3. âœ… **Script de restauraciÃ³n**
   ```bash
   # scripts/restore_backup.sh
   # Uso: ./scripts/restore_backup.sh [backup_file.sql.gz]
   ```
   - Descargar desde GitHub Artifacts
   - Restaurar a PostgreSQL
   - Documentado en README

4. âœ… **Verificar workflow de importaciÃ³n histÃ³rica**
   - Confirmar que `.github/workflows/import-historico.yml` funciona con Docker
   - Test manual: importar 1 mes de datos (ej: COT_2024-12.zip)
   - Validar detecciÃ³n de duplicados

**Criterios de Ã©xito:**
- [ ] Deploy exitoso con backup pre/post
- [ ] Backup subido a GitHub Artifacts automÃ¡ticamente
- [ ] Script `restore_backup.sh` funcional y documentado
- [ ] ImportaciÃ³n histÃ³rica mensual sin duplicados

**Archivos a crear/modificar:**
- `scripts/restore_backup.sh` (nuevo)
- `.github/workflows/ci-cd.yml` (mejorar backup steps)
- `.github/workflows/backup-to-artifacts.yml` (nuevo, semanal)
- `docs/DISASTER_RECOVERY.md` (nuevo)

**Entregable:** Deploys seguros, backups automÃ¡ticos, capacidad de disaster recovery.

---

### FASE 2: OptimizaciÃ³n de Base de Datos (3-4 dÃ­as) ğŸš€

**Objetivo:** BD rÃ¡pida para 10M+ registros, queries en <1s.

**Tareas:**
1. âœ… **Auditar Ã­ndices existentes**
   - Revisar `scripts/create_indexes.py`
   - Ejecutar `EXPLAIN ANALYZE` en queries lentas
   - Identificar Ã­ndices faltantes

2. âœ… **Particionamiento de `historico_licitaciones`**
   - Script de migraciÃ³n: `scripts/partition_historico.py`
   - Crear particiones mensuales desde 2020 hasta presente
   - Idempotente (detectar si ya estÃ¡ particionada)
   - Ejecutar en horario de baja actividad

3. âœ… **Optimizar queries lentas**
   - Habilitar `pg_stat_statements` en PostgreSQL
   - Identificar top 10 queries mÃ¡s lentas
   - Reescribir queries N+1 en `ml_precio_optimo.py` y `rag_historico.py`
   - Agregar logging de duraciÃ³n de queries (EXPLAIN ANALYZE en modo debug)

4. âœ… **Configurar Redis**
   - Agregar servicio Redis al docker-compose
   - Actualizar `redis_cache.py` para cachÃ© de ML
   - Cachear: resultados ML (TTL 1h), listados (TTL 15min), embeddings (TTL 24h)
   - MÃ©tricas de cache hit rate

**Criterios de Ã©xito:**
- [ ] Queries de anÃ¡lisis ML <1s en p95
- [ ] BÃºsqueda RAG <2s en p95
- [ ] Particionamiento activo y funcional
- [ ] Redis operativo con hit rate >60%

**Archivos a crear/modificar:**
- `scripts/partition_historico.py` (nuevo)
- `scripts/create_indexes.py` (actualizar con Ã­ndices nuevos)
- `docker-compose.yml` (agregar Redis)
- `src/redis_cache.py` (mejorar con TTL configurables)
- `src/ml_precio_optimo.py` (optimizar queries)
- `src/rag_historico.py` (optimizar queries)

**Entregable:** Queries <1s, experiencia de usuario fluida, BD lista para escalar.

---

### FASE 3: Monitoreo y Observabilidad (2 dÃ­as) ğŸ“Š

**Objetivo:** Visibilidad total de lo que pasa en producciÃ³n.

**Tareas:**
1. âœ… **Instrumentar cÃ³digo con Prometheus**
   - Crear `src/metrics_server.py` con endpoint `/metrics`
   - MÃ©tricas de negocio: comandos, suscripciones, conversiÃ³n
   - MÃ©tricas de performance: latencia ML, cache hit rate

2. âœ… **Configurar Prometheus scraping**
   - Actualizar `/devops/monitoring/prometheus/prometheus.yml`
   - Agregar jobs: compra_agil_bot, compra_agil_scraper
   - Labels para filtrar por servicio

3. âœ… **Crear dashboard en Grafana**
   - `grafana/dashboards/compra_agil.json`
   - Paneles: usuarios activos, comandos/s, latencia ML, cache hit rate
   - Panel de conversiÃ³n: features bloqueadas vs upgrades

4. âœ… **Configurar alertas vÃ­a Telegram**
   - `src/monitoring/alerts.py`
   - Alertas: disco >90%, queue >100, nuevo suscriptor pago
   - Configurar `ADMIN_CHAT_ID` en `.env`

5. âœ… **Agregar healthchecks**
   - Bot: HTTP check a `/metrics`
   - Scraper: PostgreSQL connection check
   - Configurar en Uptime Kuma

**Criterios de Ã©xito:**
- [ ] MÃ©tricas visibles en Prometheus
- [ ] Dashboard de Grafana funcional con datos reales
- [ ] Alertas de Telegram funcionando
- [ ] Todos los servicios `healthy` en `docker ps`

**Archivos a crear/modificar:**
- `src/metrics_server.py` (nuevo)
- `src/monitoring/alerts.py` (nuevo)
- `src/logger_config.py` (nuevo, JSON formatter)
- `docker-compose.yml` (healthchecks y labels Prometheus)
- `/devops/monitoring/prometheus/prometheus.yml` (actualizar)
- `/devops/grafana/dashboards/compra_agil.json` (nuevo)

**Entregable:** Dashboard en vivo, alertas automÃ¡ticas, visibilidad de mÃ©tricas de negocio.

---

### FASE 4: Workers y Queue (3-4 dÃ­as) âš™ï¸

**Objetivo:** Bot siempre responsivo, tareas pesadas en background.

**Tareas:**
1. âœ… **Configurar Celery**
   - Crear `src/tasks.py` con configuraciÃ³n Celery
   - Definir queues: `ml`, `scraping`, `exports`
   - Configurar Redis como broker

2. âœ… **Migrar tareas pesadas a Celery**
   - `/precio` â†’ `tasks.calcular_precio_optimo.delay()`
   - `/rag` â†’ `tasks.buscar_rag_historico.delay()`
   - `/generar_excel` â†’ `tasks.generar_excel_export.delay()`
   - Scraper â†’ `tasks.ejecutar_scraper.delay()` con Celery Beat

3. âœ… **Actualizar docker-compose**
   - Agregar servicios: `celery-worker-ml`, `celery-worker-scraping`, `celery-beat`
   - Configurar concurrencia: ML (2 workers), scraping (1 worker)

4. âœ… **Implementar notificaciones asÃ­ncronas**
   - Cuando tarea termina, notificar al usuario via bot
   - Callbacks para tareas exitosas/fallidas
   - Retry automÃ¡tico con backoff exponencial

5. âœ… **Monitoreo de workers**
   - MÃ©tricas de Celery en Prometheus
   - Panel de Grafana: queue length, workers activos, latencia de tareas
   - Alerta si queue >100 tareas

**Criterios de Ã©xito:**
- [ ] Bot responde instantÃ¡neamente (<200ms)
- [ ] AnÃ¡lisis ML se ejecutan en background
- [ ] Notificaciones asÃ­ncronas funcionando
- [ ] Scraper ejecuta cada 6h automÃ¡ticamente vÃ­a Celery Beat

**Archivos a crear/modificar:**
- `src/tasks.py` (nuevo)
- `src/bot_ml_commands.py` (migrar a async con Celery)
- `src/scheduler.py` (migrar a Celery Beat)
- `docker-compose.yml` (agregar workers y beat)
- `requirements.txt` (agregar celery, redis)

**Entregable:** Bot sÃºper responsivo, tareas pesadas no bloquean, mejor UX.

---

### FASE 5: Features de IA Premium (5-7 dÃ­as) ğŸ¤–

**Objetivo:** DiferenciaciÃ³n competitiva, valor agregado real.

**Prioridad de implementaciÃ³n:**

**5.1 AnÃ¡lisis de Precios Mejorado (Quick Win - 1 dÃ­a)**
- Mejorar `ml_precio_optimo.py` con insights especÃ­ficos
- AÃ±adir: precio por organismo, por regiÃ³n, competidores frecuentes
- Recomendaciones accionables basadas en histÃ³rico

**5.2 Scoring de Probabilidad de Ganar (Alto Valor - 2 dÃ­as)**
- Entrenar modelo Random Forest con histÃ³rico
- Features: precio ratio, experiencia, regiÃ³n, tamaÃ±o proveedor
- Nuevo comando: `/scoring <licitacion_id>`
- ExplicaciÃ³n de factores clave (feature importance)

**5.3 Matching SemÃ¡ntico con Embeddings (Diferenciador - 2 dÃ­as)**
- Instalar extensiÃ³n `pgvector` en PostgreSQL
- Generar embeddings de licitaciones con Gemini
- Tabla `licitacion_embeddings` con Ã­ndice IVFFlat
- Migrar alertas a semantic search
- Comando: `/alertas_ia <descripcion_empresa>`

**5.4 Generador de Propuestas (Premium Killer Feature - 2 dÃ­as)**
- Nuevo comando: `/generar_propuesta <licitacion_id>`
- Validar tier PYME/PROFESIONAL
- Prompt engineering con contexto de licitaciÃ³n + perfil empresa
- Exportar a PDF/DOCX
- Tracking de uso (5/mes para PYME, ilimitado para PROFESIONAL)

**Criterios de Ã©xito:**
- [ ] AnÃ¡lisis de precios retorna 3 insights accionables
- [ ] Scoring predice con >70% accuracy
- [ ] Alertas semÃ¡nticas encuentran >2x mÃ¡s matches relevantes
- [ ] Generador crea propuestas de calidad (validar manualmente)

**Archivos a crear/modificar:**
- `src/ml_precio_optimo_v2.py` (nuevo)
- `src/ml_win_probability.py` (nuevo, modelo scoring)
- `src/semantic_search.py` (nuevo, embeddings)
- `src/generador_propuestas.py` (nuevo)
- `scripts/train_win_model.py` (nuevo, entrenamiento)
- `scripts/generate_embeddings.py` (nuevo, batch embeddings)
- `migrations/add_pgvector.sql` (nuevo)

**Entregable:** Features premium implementadas, tier PYME/PROFESIONAL con valor real.

---

### FASE 6: MonetizaciÃ³n y Pagos (4-5 dÃ­as) ğŸ’°

**Objetivo:** Convertir usuarios gratis a pagos, revenue real.

**Tareas:**

**6.1 Integrar Pasarela de Pago (2 dÃ­as)**
- Integrar Flow (recomendado para Chile) o Stripe
- Tabla `payments` para transacciones
- Webhook para confirmaciÃ³n de pago
- Comando: `/upgrade` con opciones de planes

**6.2 Sistema de FacturaciÃ³n (1 dÃ­a)**
- Generar boleta/factura automÃ¡tica con datos chilenos
- Almacenar en tabla `invoices`
- Enviar por Telegram como PDF

**6.3 GestiÃ³n de Suscripciones (1 dÃ­a)**
- Auto-renovaciÃ³n mensual
- Downgrade automÃ¡tico si falla pago
- Notificaciones: 3 dÃ­as antes de vencimiento
- Comando: `/mis_suscripciones`

**6.4 Analytics de ConversiÃ³n (1 dÃ­a)**
- Funnel en Grafana: FREE â†’ Bloqueado â†’ Upgrade â†’ Pago
- MÃ©tricas: tasa de conversiÃ³n, MRR, churn rate
- A/B testing de precios (opcional)

**Criterios de Ã©xito:**
- [ ] Pago exitoso actualiza tier del usuario
- [ ] Factura se genera automÃ¡ticamente
- [ ] Auto-renovaciÃ³n funciona correctamente
- [ ] Dashboard de conversiÃ³n operativo

**Archivos a crear/modificar:**
- `src/payments.py` (nuevo, integraciÃ³n Flow/Stripe)
- `src/invoicing.py` (nuevo, generaciÃ³n facturas)
- `src/bot_upgrade_commands.py` (nuevo)
- `migrations/add_payments_tables.sql` (nuevo)
- `.env.example` (agregar secrets de Flow/Stripe)

**Entregable:** Sistema de pagos funcionando, primeros clientes pagos.

---

### FASE 7: Escalabilidad Horizontal (Futuro) ğŸ“ˆ

**CuÃ¡ndo:** Cuando tengas >500 usuarios activos diarios o el VPS estÃ© al 80% CPU constantemente.

**Tareas:**
1. âœ… **Migrar a multi-servidor**
   - Load balancer (Traefik ya lo tienes)
   - MÃºltiples workers Celery en servidores separados
   - Redis en modo cluster

2. âœ… **BD administrada**
   - PostgreSQL en servicio managed (DigitalOcean, AWS RDS)
   - Backups automÃ¡ticos, rÃ©plicas read
   - ConexiÃ³n pooling (PgBouncer)

3. âœ… **CDN para assets**
   - Si implementas dashboard web
   - CloudFlare (gratis) o AWS CloudFront

4. âœ… **Auto-scaling**
   - Docker Swarm (mÃ¡s simple que Kubernetes)
   - O Kubernetes si crece mucho mÃ¡s

**Criterios de Ã©xito:**
- [ ] Sistema maneja 10,000+ usuarios concurrentes
- [ ] Latencia p95 <500ms bajo carga
- [ ] Uptime >99.9%

**Entregable:** Sistema listo para escalar masivamente.

---

## Anexos

### MÃ©tricas de Ã‰xito del Proyecto

**TÃ©cnicas:**
- Uptime: >99.5%
- Queries de BD: p95 <1s
- Latencia de bot: p95 <200ms
- Cache hit rate: >60%

**Negocio:**
- Usuarios activos mensuales: meta 1,000 en 3 meses
- Tasa de conversiÃ³n FREE â†’ PAGO: meta 5%
- MRR (Monthly Recurring Revenue): meta $500,000 CLP en 6 meses
- Churn rate: <10% mensual

### Dependencias TÃ©cnicas

**Python packages nuevos:**
```
celery==5.3.4
redis==5.0.1
prometheus-client==0.19.0
pgvector==0.2.3
scikit-learn==1.3.2
joblib==1.3.2
```

**PostgreSQL extensions:**
- `pg_trgm` (ya instalada probablemente)
- `pgvector` (nueva)
- `pg_stat_statements` (para query profiling)

**Infraestructura:**
- Redis 7.x (nuevo servicio Docker)
- Espacio en disco: +20GB para backups
- RAM adicional: ~500MB (Celery workers + Redis)

### Riesgos y Mitigaciones

| Riesgo | Impacto | Probabilidad | MitigaciÃ³n |
|--------|---------|--------------|------------|
| Particionamiento corrompe datos | Alto | Baja | Backup completo antes, rollback plan |
| Celery workers colapsan servidor | Medio | Media | Monitoreo de recursos, lÃ­mite de concurrencia |
| IntegraciÃ³n de pagos falla | Alto | Baja | Testing exhaustivo en sandbox, validaciÃ³n manual |
| Embeddings consumen mucha API | Bajo | Alta | Cachear embeddings, batch processing |
| Modelo ML overfitting | Medio | Media | ValidaciÃ³n cruzada, monitoreo de accuracy |

---

## ConclusiÃ³n

Este plan transforma CompraAgil de un bot funcional a un SaaS escalable y monetizable con:

1. **Persistencia bulletproof**: Nunca perder datos histÃ³ricos
2. **Performance optimizado**: Queries <1s, bot siempre responsivo
3. **Features premium**: Matching IA, scoring, generador de propuestas
4. **Observabilidad completa**: MÃ©tricas de negocio en tiempo real
5. **MonetizaciÃ³n clara**: Sistema de pagos y facturaciÃ³n

**PrÃ³ximo paso:** Comenzar con Fase 0 (EstabilizaciÃ³n) y Fase 1 (Persistencia).

---

**Ãšltima actualizaciÃ³n:** 2025-12-28
**VersiÃ³n:** 1.0
